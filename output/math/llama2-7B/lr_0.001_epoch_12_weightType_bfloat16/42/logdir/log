Args: 
lr: 0.001 
weight_decay: 0.0 
model_type: llama2-7B 
warmup_ratio: 0 
seed: 42 
per_device_train_batch_size: 2 
per_device_eval_batch_size: 2 
gradient_accumulation_steps: 1 
num_train_epochs: 12 
save_dir: /home/lwh/code/SuperRED/output/math/llama2-7B/lr_0.001_epoch_12_weightType_bfloat16/42/save_models 
layer_type: all 

Args: 
lr: 0.001 
weight_decay: 0.0 
model_type: llama2-7B 
warmup_ratio: 0 
seed: 42 
per_device_train_batch_size: 2 
per_device_eval_batch_size: 2 
gradient_accumulation_steps: 1 
num_train_epochs: 12 
save_dir: /home/lwh/code/SuperRED/output/math/llama2-7B/lr_0.001_epoch_12_weightType_bfloat16/42/save_models 
layer_type: all 

Args: 
lr: 0.001 
weight_decay: 0.0 
model_type: llama2-7B 
warmup_ratio: 0 
seed: 42 
per_device_train_batch_size: 2 
per_device_eval_batch_size: 2 
gradient_accumulation_steps: 1 
num_train_epochs: 12 
save_dir: /home/lwh/code/SuperRED/output/math/llama2-7B/lr_0.001_epoch_12_weightType_bfloat16/42/save_models 
layer_type: all 

Args: 
lr: 0.001 
weight_decay: 0.0 
model_type: llama2-7B 
warmup_ratio: 0 
seed: 42 
per_device_train_batch_size: 2 
per_device_eval_batch_size: 2 
gradient_accumulation_steps: 1 
num_train_epochs: 12 
save_dir: /home/lwh/code/SuperRED/output/math/llama2-7B/lr_0.001_epoch_12_weightType_bfloat16/42/save_models 
layer_type: all 

Args: 
lr: 0.001 
weight_decay: 0.0 
model_type: llama2-7B 
warmup_ratio: 0 
seed: 42 
per_device_train_batch_size: 2 
per_device_eval_batch_size: 2 
gradient_accumulation_steps: 1 
num_train_epochs: 12 
save_dir: /home/lwh/code/SuperRED/output/math/llama2-7B/lr_0.001_epoch_12_weightType_bfloat16/42/save_models 
layer_type: all 

